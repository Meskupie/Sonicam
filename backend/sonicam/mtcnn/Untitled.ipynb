{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Tensorflow implementation of the face detection / alignment algorithm found at\n",
    "https://github.com/kpzhang93/MTCNN_face_detection_alignment\n",
    "\"\"\"\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2016 David Sandberg\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six import string_types, iteritems\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from math import floor\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def layer(op):\n",
    "    \"\"\"Decorator for composable network layers.\"\"\"\n",
    "\n",
    "    def layer_decorated(self, *args, **kwargs):\n",
    "        # Automatically set a name if not provided.\n",
    "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n",
    "        # Figure out the layer inputs.\n",
    "        if len(self.terminals) == 0:\n",
    "            raise RuntimeError('No input variables found for layer %s.' % name)\n",
    "        elif len(self.terminals) == 1:\n",
    "            layer_input = self.terminals[0]\n",
    "        else:\n",
    "            layer_input = list(self.terminals)\n",
    "        # Perform the operation and get the output.\n",
    "        layer_output = op(self, layer_input, *args, **kwargs)\n",
    "        # Add to layer LUT.\n",
    "        self.layers[name] = layer_output\n",
    "        # This output is now the input for the next layer.\n",
    "        self.feed(layer_output)\n",
    "        # Return self for chained calls.\n",
    "        return self\n",
    "\n",
    "    return layer_decorated\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, inputs, trainable=True):\n",
    "        # The input nodes for this network\n",
    "        self.inputs = inputs\n",
    "        # The current list of terminal nodes\n",
    "        self.terminals = []\n",
    "        # Mapping from layer names to layers\n",
    "        self.layers = dict(inputs)\n",
    "        # If true, the resulting variables are set as trainable\n",
    "        self.trainable = trainable\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Construct the network. \"\"\"\n",
    "        raise NotImplementedError('Must be implemented by the subclass.')\n",
    "\n",
    "    def load(self, data_path, session, ignore_missing=False):\n",
    "        \"\"\"Load network weights.\n",
    "        data_path: The path to the numpy-serialized network weights\n",
    "        session: The current TensorFlow session\n",
    "        ignore_missing: If true, serialized weights for missing layers are ignored.\n",
    "        \"\"\"\n",
    "        data_dict = np.load(data_path, encoding='latin1').item() #pylint: disable=no-member\n",
    "\n",
    "        for op_name in data_dict:\n",
    "            with tf.variable_scope(op_name, reuse=True):\n",
    "                for param_name, data in iteritems(data_dict[op_name]):\n",
    "                    try:\n",
    "                        var = tf.get_variable(param_name)\n",
    "                        session.run(var.assign(data))\n",
    "                    except ValueError:\n",
    "                        if not ignore_missing:\n",
    "                            raise\n",
    "\n",
    "    def feed(self, *args):\n",
    "        \"\"\"Set the input(s) for the next operation by replacing the terminal nodes.\n",
    "        The arguments can be either layer names or the actual layers.\n",
    "        \"\"\"\n",
    "        assert len(args) != 0\n",
    "        self.terminals = []\n",
    "        for fed_layer in args:\n",
    "            if isinstance(fed_layer, string_types):\n",
    "                try:\n",
    "                    fed_layer = self.layers[fed_layer]\n",
    "                except KeyError:\n",
    "                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n",
    "            self.terminals.append(fed_layer)\n",
    "        return self\n",
    "\n",
    "    def get_output(self):\n",
    "        \"\"\"Returns the current network output.\"\"\"\n",
    "        return self.terminals[-1]\n",
    "\n",
    "    def get_unique_name(self, prefix):\n",
    "        \"\"\"Returns an index-suffixed unique name for the given prefix.\n",
    "        This is used for auto-generating layer names based on the type-prefix.\n",
    "        \"\"\"\n",
    "        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n",
    "        return '%s_%d' % (prefix, ident)\n",
    "\n",
    "    def make_var(self, name, shape):\n",
    "        \"\"\"Creates a new TensorFlow variable.\"\"\"\n",
    "        return tf.get_variable(name, shape, trainable=self.trainable)\n",
    "\n",
    "    def validate_padding(self, padding):\n",
    "        \"\"\"Verifies that the padding is one of the supported ones.\"\"\"\n",
    "        assert padding in ('SAME', 'VALID')\n",
    "\n",
    "    @layer\n",
    "    def conv(self,\n",
    "             inp,\n",
    "             k_h,\n",
    "             k_w,\n",
    "             c_o,\n",
    "             s_h,\n",
    "             s_w,\n",
    "             name,\n",
    "             relu=True,\n",
    "             padding='SAME',\n",
    "             group=1,\n",
    "             biased=True):\n",
    "        # Verify that the padding is acceptable\n",
    "        self.validate_padding(padding)\n",
    "        # Get the number of channels in the input\n",
    "        c_i = int(inp.get_shape()[-1])\n",
    "        # Verify that the grouping parameter is valid\n",
    "        assert c_i % group == 0\n",
    "        assert c_o % group == 0\n",
    "        # Convolution for a given input and kernel\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            kernel = self.make_var('weights', shape=[k_h, k_w, c_i // group, c_o])\n",
    "            # This is the common-case. Convolve the input without any further complications.\n",
    "            output = convolve(inp, kernel)\n",
    "            # Add the biases\n",
    "            if biased:\n",
    "                biases = self.make_var('biases', [c_o])\n",
    "                output = tf.nn.bias_add(output, biases)\n",
    "            if relu:\n",
    "                # ReLU non-linearity\n",
    "                output = tf.nn.relu(output, name=scope.name)\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def prelu(self, inp, name):\n",
    "        with tf.variable_scope(name):\n",
    "            i = int(inp.get_shape()[-1])\n",
    "            alpha = self.make_var('alpha', shape=(i,))\n",
    "            output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n",
    "        return output\n",
    "\n",
    "    @layer\n",
    "    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.max_pool(inp,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def fc(self, inp, num_out, name, relu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            input_shape = inp.get_shape()\n",
    "            if input_shape.ndims == 4:\n",
    "                # The input is spatial. Vectorize it first.\n",
    "                dim = 1\n",
    "                for d in input_shape[1:].as_list():\n",
    "                    dim *= int(d)\n",
    "                feed_in = tf.reshape(inp, [-1, dim])\n",
    "            else:\n",
    "                feed_in, dim = (inp, input_shape[-1].value)\n",
    "            weights = self.make_var('weights', shape=[dim, num_out])\n",
    "            biases = self.make_var('biases', [num_out])\n",
    "            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n",
    "            fc = op(feed_in, weights, biases, name=name)\n",
    "            return fc\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Multi dimensional softmax,\n",
    "    refer to https://github.com/tensorflow/tensorflow/issues/210\n",
    "    compute softmax along the dimension of target\n",
    "    the native softmax only supports batch_size x dimension\n",
    "    \"\"\"\n",
    "    @layer\n",
    "    def softmax(self, target, axis, name=None):\n",
    "        max_axis = tf.reduce_max(target, axis, keepdims=True)\n",
    "        target_exp = tf.exp(target-max_axis)\n",
    "        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n",
    "        softmax = tf.div(target_exp, normalize, name)\n",
    "        return softmax\n",
    "    \n",
    "class PNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='PReLU1')\n",
    "             .max_pool(2, 2, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='PReLU2')\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='PReLU3')\n",
    "             .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1')\n",
    "             .softmax(3,name='prob1'))\n",
    "\n",
    "        (self.feed('PReLU3') #pylint: disable=no-value-for-parameter\n",
    "             .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))\n",
    "        \n",
    "class RNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 28, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 48, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(2, 2, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .fc(128, relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(2, relu=False, name='conv5-1')\n",
    "             .softmax(1,name='prob1'))\n",
    "\n",
    "        (self.feed('prelu4') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv5-2'))\n",
    "\n",
    "class ONet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .max_pool(2, 2, 2, 2, name='pool3')\n",
    "             .conv(2, 2, 128, 1, 1, padding='VALID', relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(256, relu=False, name='conv5')\n",
    "             .prelu(name='prelu5')\n",
    "             .fc(2, relu=False, name='conv6-1')\n",
    "             .softmax(1, name='prob1'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv6-2'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(10, relu=False, name='conv6-3'))\n",
    "\n",
    "class Detector:\n",
    "    def __init__(self, sess):\n",
    "        self.time_log = []\n",
    "\n",
    "        with tf.variable_scope('pnet'):\n",
    "            data = tf.placeholder(tf.float32, (None,None,None,3), 'input')\n",
    "            pnet = PNet({'data':data})\n",
    "            pnet.load('det1.npy', sess)\n",
    "        with tf.variable_scope('rnet'):\n",
    "            data = tf.placeholder(tf.float32, (None,24,24,3), 'input')\n",
    "            rnet = RNet({'data':data})\n",
    "            rnet.load('det2.npy', sess)\n",
    "        with tf.variable_scope('onet'):\n",
    "            data = tf.placeholder(tf.float32, (None,48,48,3), 'input')\n",
    "            onet = ONet({'data':data})\n",
    "            onet.load('det3.npy', sess)\n",
    "            \n",
    "        self.pnet_fun = lambda img : sess.run(('pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'), feed_dict={'pnet/input:0':img})\n",
    "        self.rnet_fun = lambda img : sess.run(('rnet/conv5-2/conv5-2:0', 'rnet/prob1:0'), feed_dict={'rnet/input:0':img})\n",
    "        self.onet_fun = lambda img : sess.run(('onet/conv6-2/conv6-2:0', 'onet/conv6-3/conv6-3:0', 'onet/prob1:0'), feed_dict={'onet/input:0':img})\n",
    "\n",
    "    def getScales(self, img, minsize=20, factor=0.709):\n",
    "        factor_count=0\n",
    "        total_boxes=np.empty((0,9))\n",
    "        points=np.empty(0)\n",
    "        h=img.shape[0]\n",
    "        w=img.shape[1]\n",
    "        minl=np.amin([h, w])\n",
    "        m=12.0/minsize\n",
    "        minl=minl*m\n",
    "        \n",
    "        scales=[]\n",
    "        while minl>=12:\n",
    "            scales += [m*np.power(factor, factor_count)]\n",
    "            minl = minl*factor\n",
    "            factor_count += 1\n",
    "        return [1/scale for scale in scales]\n",
    "\n",
    "    # function [boundingbox] = bbreg(boundingbox,reg)\n",
    "    def bbreg(self, boundingbox,reg):\n",
    "        \"\"\"Calibrate bounding boxes\"\"\"\n",
    "        if reg.shape[1]==1:\n",
    "            reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n",
    "\n",
    "        w = boundingbox[:,2]-boundingbox[:,0]+1\n",
    "        h = boundingbox[:,3]-boundingbox[:,1]+1\n",
    "        b1 = boundingbox[:,0]+reg[:,0]*w\n",
    "        b2 = boundingbox[:,1]+reg[:,1]*h\n",
    "        b3 = boundingbox[:,2]+reg[:,2]*w\n",
    "        b4 = boundingbox[:,3]+reg[:,3]*h\n",
    "        boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n",
    "        return boundingbox\n",
    "     \n",
    "    def generateBoundingBox(self, imap, reg, scale, t):\n",
    "        \"\"\"Use heatmap to generate bounding boxes\"\"\"\n",
    "        stride=2\n",
    "        cellsize=12\n",
    "\n",
    "        imap = np.transpose(imap)\n",
    "        dx1 = np.transpose(reg[:,:,0])\n",
    "        dy1 = np.transpose(reg[:,:,1])\n",
    "        dx2 = np.transpose(reg[:,:,2])\n",
    "        dy2 = np.transpose(reg[:,:,3])\n",
    "        y, x = np.where(imap >= t)\n",
    "        if y.shape[0]==1:\n",
    "            dx1 = np.flipud(dx1)\n",
    "            dy1 = np.flipud(dy1)\n",
    "            dx2 = np.flipud(dx2)\n",
    "            dy2 = np.flipud(dy2)\n",
    "        score = imap[(y,x)]\n",
    "        reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n",
    "        if reg.size==0:\n",
    "            reg = np.empty((0,3))\n",
    "        bb = np.transpose(np.vstack([y,x]))\n",
    "        q1 = np.fix((stride*bb+1)/scale)\n",
    "        q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n",
    "        boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n",
    "        return boundingbox, reg\n",
    "     \n",
    "    # function pick = nms(boxes,threshold,type)\n",
    "    def nms(self, boxes, threshold, method):\n",
    "        if boxes.size==0:\n",
    "            return np.empty((0,3))\n",
    "        x1 = boxes[:,0]\n",
    "        y1 = boxes[:,1]\n",
    "        x2 = boxes[:,2]\n",
    "        y2 = boxes[:,3]\n",
    "        s = boxes[:,4]\n",
    "        area = (x2-x1+1) * (y2-y1+1)\n",
    "        I = np.argsort(s)\n",
    "        pick = np.zeros_like(s, dtype=np.int16)\n",
    "        counter = 0\n",
    "        while I.size>0:\n",
    "            i = I[-1]\n",
    "            pick[counter] = i\n",
    "            counter += 1\n",
    "            idx = I[0:-1]\n",
    "            xx1 = np.maximum(x1[i], x1[idx])\n",
    "            yy1 = np.maximum(y1[i], y1[idx])\n",
    "            xx2 = np.minimum(x2[i], x2[idx])\n",
    "            yy2 = np.minimum(y2[i], y2[idx])\n",
    "            w = np.maximum(0.0, xx2-xx1+1)\n",
    "            h = np.maximum(0.0, yy2-yy1+1)\n",
    "            inter = w * h\n",
    "            if method is 'Min':\n",
    "                o = inter / np.minimum(area[i], area[idx])\n",
    "            else:\n",
    "                o = inter / (area[i] + area[idx] - inter)\n",
    "            I = I[np.where(o<=threshold)]\n",
    "        pick = pick[0:counter]\n",
    "        return pick\n",
    "\n",
    "    # function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n",
    "    def pad(self, total_boxes, w, h):\n",
    "        \"\"\"Compute the padding coordinates (pad the bounding boxes to square)\"\"\"\n",
    "        tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n",
    "        tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n",
    "        numbox = total_boxes.shape[0]\n",
    "\n",
    "        dx = np.ones((numbox), dtype=np.int32)\n",
    "        dy = np.ones((numbox), dtype=np.int32)\n",
    "        edx = tmpw.copy().astype(np.int32)\n",
    "        edy = tmph.copy().astype(np.int32)\n",
    "\n",
    "        x = total_boxes[:,0].copy().astype(np.int32)\n",
    "        y = total_boxes[:,1].copy().astype(np.int32)\n",
    "        ex = total_boxes[:,2].copy().astype(np.int32)\n",
    "        ey = total_boxes[:,3].copy().astype(np.int32)\n",
    "\n",
    "        tmp = np.where(ex>w)\n",
    "        edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n",
    "        ex[tmp] = w\n",
    "        \n",
    "        tmp = np.where(ey>h)\n",
    "        edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n",
    "        ey[tmp] = h\n",
    "\n",
    "        tmp = np.where(x<1)\n",
    "        dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n",
    "        x[tmp] = 1\n",
    "\n",
    "        tmp = np.where(y<1)\n",
    "        dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n",
    "        y[tmp] = 1\n",
    "        \n",
    "        return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n",
    "\n",
    "    # function [bboxA] = rerec(bboxA)\n",
    "    def rerec(self, bboxA):\n",
    "        \"\"\"Convert bboxA to square.\"\"\"\n",
    "        h = bboxA[:,3]-bboxA[:,1]\n",
    "        w = bboxA[:,2]-bboxA[:,0]\n",
    "        l = np.maximum(w, h)\n",
    "        bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n",
    "        bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n",
    "        bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n",
    "        return bboxA\n",
    "\n",
    "\n",
    "    # =====================================\n",
    "    # Functions for profiling the algorithm\n",
    "    # =====================================\n",
    "    def tic(self):\n",
    "        self.time_start = time.time()\n",
    "        self.time_array = [('start',0)]\n",
    "\n",
    "    def ti(self, name, out=False):\n",
    "        self.time_array.append((name,time.time()-self.time_start))\n",
    "        if out:\n",
    "            print(self.time_array[-1](1))\n",
    "\n",
    "    def toc(self, name='End'):\n",
    "        self.ti(name)\n",
    "        self.time_log.append(self.time_array)\n",
    "        \n",
    "    def tic_clear(self):\n",
    "        self.time_log = []\n",
    "\n",
    "    def toc_report(self):\n",
    "        unzipped_report = list(zip(*self.time_log))\n",
    "        self.tic_clear()\n",
    "        mean_report = []\n",
    "        for item in unzipped_report:\n",
    "            [name,times] = list(zip(*item))\n",
    "            mean_report.append( (name[0],np.array(times)) )\n",
    "        self.toc_draw(mean_report)\n",
    "    \n",
    "    def toc_draw(self,report):\n",
    "        if len(report) == 1:\n",
    "            report = report[0]\n",
    "        print('====================================')\n",
    "        print('Results processed from '+str(report[0][1].size)+' test(s)')\n",
    "        search_sum_names = ['First Net Ran', 'Second Net Ran', 'Third Net Ran']\n",
    "        search_sum = 0\n",
    "        for i in range(len(report)):\n",
    "            max_name_len = np.array([len(line[0]) for line in report]).max()\n",
    "            if i > 0:\n",
    "                dt = np.array(report[i][1]-report[i-1][1])\n",
    "                pad = max_name_len-len(report[i][0])\n",
    "                print(str(report[i][0])+': '+' '*pad+'mean: '+str(int(round(dt.mean()*1000)))+' ms ('+\n",
    "                      str(int(round(100*dt.mean()/np.array(report[-1][1]).mean())))+'%), stddev: '+\n",
    "                      str(round(dt.std()*1000,1))+' ms')\n",
    "                if report[i][0] in search_sum_names:\n",
    "                    search_sum = search_sum+dt.mean()\n",
    "\n",
    "        print('')\n",
    "        print('Total: '+str(round(np.array(report[-1][1]).mean()*1000,2))+' ms, stddev: '+\n",
    "            str(round(np.array(report[-1][1]).std()*1000,1)))\n",
    "        print('Tensorflow Percentage: '+str(int(round(100*search_sum/np.array(report[-1][1]).mean())))+'%')\n",
    "        print('====================================')\n",
    "        \n",
    "    def detect(self, img, threshold=[0.6, 0.7, 0.7], scales=None, verbose=False):\n",
    "        \"\"\"Detects faces in an image, and returns bounding boxes and points for them.\n",
    "        img: input image\n",
    "        minsize: minimum faces' size\n",
    "        pnet, rnet, onet: caffemodel\n",
    "        threshold: threshold=[th1, th2, th3], th1-3 are three steps's threshold\n",
    "        factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n",
    "        \"\"\"\n",
    "        self.tic()\n",
    "        pnet = self.pnet_fun\n",
    "        rnet = self.rnet_fun\n",
    "        onet = self.onet_fun\n",
    "        \n",
    "\n",
    "        if not scales == None:\n",
    "            frames = []\n",
    "            for i in range(len(scales)):\n",
    "                hs=int(round(h*scales[i]))\n",
    "                ws=int(round(w*scales[i]))\n",
    "                if scales_src[i] == -1:\n",
    "                    im_data = self.imresample(img, (hs, ws))\n",
    "                else:\n",
    "                    im_data = self.imresample(frames[scales_src[i]], (hs, ws))\n",
    "                frames.append(im_data)\n",
    "\n",
    "            self.ti('Frames Grabed')\n",
    "            # first stage\n",
    "            for i in range(len(frames)):\n",
    "                im_data = (frames[i]-127.5)*0.0078125\n",
    "                img_x = np.expand_dims(im_data, 0)\n",
    "                img_y = np.transpose(img_x, (0,2,1,3))\n",
    "                self.ti('First Net Ready')\n",
    "                out = pnet(img_y)\n",
    "                self.ti('First Net Ran')\n",
    "                out0 = np.transpose(out[0], (0,2,1,3))\n",
    "                out1 = np.transpose(out[1], (0,2,1,3))\n",
    "                \n",
    "                boxes, _ = self.generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scales[i], threshold[0])\n",
    "                \n",
    "                # inter-scale nms\n",
    "                pick = self.nms(boxes.copy(), 0.5, 'Union')\n",
    "                if boxes.size>0 and pick.size>0:\n",
    "                    boxes = boxes[pick,:]\n",
    "                    total_boxes = np.append(total_boxes, boxes, axis=0)\n",
    "            \n",
    "            self.ti('First Net Processed')\n",
    "            \n",
    "        numbox = total_boxes.shape[0]\n",
    "\n",
    "        if verbose: print('First stage raw box count: '+str(numbox))\n",
    "\n",
    "        self.ti('First Box Process Ready')\n",
    "        if numbox>0:\n",
    "            pick = self.nms(total_boxes.copy(), 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            regw = total_boxes[:,2]-total_boxes[:,0]\n",
    "            regh = total_boxes[:,3]-total_boxes[:,1]\n",
    "            qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n",
    "            qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n",
    "            qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n",
    "            qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n",
    "            total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n",
    "            total_boxes = self.rerec(total_boxes.copy())\n",
    "            total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n",
    "            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = self.pad(total_boxes.copy(), w, h)\n",
    "\n",
    "        numbox = total_boxes.shape[0]\n",
    "        self.ti('First Box Process Ran')\n",
    "        if verbose: print('First stage thresholded box count: '+str(numbox))\n",
    "\n",
    "        if numbox>0:\n",
    "            # second stage\n",
    "            tempimg = np.zeros((24,24,3,numbox))\n",
    "            for k in range(0,numbox):\n",
    "                tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "                tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "                if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                    tempimg[:,:,:,k] = self.imresample(tmp, (24, 24))\n",
    "                else:\n",
    "                    return np.empty()\n",
    "            tempimg = (tempimg-127.5)*0.0078125\n",
    "            tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "            self.ti('Second Net Ready')\n",
    "            out = rnet(tempimg1)\n",
    "            self.ti('Second Net Ran')\n",
    "            out0 = np.transpose(out[0])\n",
    "            out1 = np.transpose(out[1])\n",
    "            score = out1[1,:]\n",
    "            ipass = np.where(score>threshold[1])\n",
    "            total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "            mv = out0[:,ipass[0]]\n",
    "            if total_boxes.shape[0]>0:\n",
    "                pick = self.nms(total_boxes, 0.7, 'Union')\n",
    "                total_boxes = total_boxes[pick,:]\n",
    "                total_boxes = self.bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n",
    "                total_boxes = self.rerec(total_boxes.copy())\n",
    "\n",
    "        numbox = total_boxes.shape[0]\n",
    "        self.ti('Second Box Process Ran')\n",
    "        if verbose: print('Second Box Count: '+str(numbox))\n",
    "\n",
    "        if numbox>0:\n",
    "            # third stage\n",
    "            total_boxes = np.fix(total_boxes).astype(np.int32)\n",
    "            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = self.pad(total_boxes.copy(), w, h)\n",
    "            tempimg = np.zeros((48,48,3,numbox))\n",
    "            for k in range(0,numbox):\n",
    "                tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "                tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "                if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                    tempimg[:,:,:,k] = self.imresample(tmp, (48, 48))\n",
    "                else:\n",
    "                    return np.empty()\n",
    "            tempimg = (tempimg-127.5)*0.0078125\n",
    "            tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "            self.ti('Third Net Ready')\n",
    "            out = onet(tempimg1)\n",
    "            self.ti('Third Net Ran')\n",
    "            out0 = np.transpose(out[0])\n",
    "            out1 = np.transpose(out[1])\n",
    "            out2 = np.transpose(out[2])\n",
    "            score = out2[1,:]\n",
    "            points = out1\n",
    "            ipass = np.where(score>threshold[2])\n",
    "            points = points[:,ipass[0]]\n",
    "            total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "            mv = out0[:,ipass[0]]\n",
    "\n",
    "            w = total_boxes[:,2]-total_boxes[:,0]+1\n",
    "            h = total_boxes[:,3]-total_boxes[:,1]+1\n",
    "            points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n",
    "            points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n",
    "            if verbose: print('Third stage raw box count: '+str(total_boxes.shape[0]))\n",
    "            if total_boxes.shape[0]>0:\n",
    "                total_boxes = self.bbreg(total_boxes.copy(), np.transpose(mv))\n",
    "                pick = self.nms(total_boxes.copy(), 0.7, 'Min')\n",
    "                total_boxes = total_boxes[pick,:]\n",
    "                points = points[:,pick]\n",
    "        \n",
    "        self.ti('Third Box Process Ran')\n",
    "        #return total_boxes, points\n",
    "\n",
    "        bounding_boxes = []\n",
    "        for bounding_box, keypoints in zip(total_boxes, points.T):\n",
    "            bounding_boxes.append({\n",
    "                    'box': [int(bounding_box[0]), int(bounding_box[1]),\n",
    "                            int(bounding_box[2]-bounding_box[0]), int(bounding_box[3]-bounding_box[1])],\n",
    "                    'confidence': bounding_box[-1],\n",
    "                    'keypoints': {\n",
    "                        'left_eye': (int(keypoints[0]), int(keypoints[5])),\n",
    "                        'right_eye': (int(keypoints[1]), int(keypoints[6])),\n",
    "                        'nose': (int(keypoints[2]), int(keypoints[7])),\n",
    "                        'mouth_left': (int(keypoints[3]), int(keypoints[8])),\n",
    "                        'mouth_right': (int(keypoints[4]), int(keypoints[9])),\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "        self.toc()\n",
    "        return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayResult(frame,results,height=1080):\n",
    "    \n",
    "    h, w = frame.shape[0:2]\n",
    "    scale = height/h\n",
    "    image = cv2.resize(frame,(int(w*scale),int(h*scale)))\n",
    "    \n",
    "    for result in results:\n",
    "        bounding_box = [int(round(x*scale)) for x in result['box']]\n",
    "        keypoints = result['keypoints']\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                      (bounding_box[0], bounding_box[1]),\n",
    "                      (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "                      (0,155,255),\n",
    "                      2)\n",
    "\n",
    "        cv2.circle(image,tuple(int(round(x*scale)) for x in keypoints['left_eye']), 1, (0,0,255), 2)\n",
    "        cv2.circle(image,tuple(int(round(x*scale)) for x in keypoints['right_eye']), 1, (0,0,255), 2)\n",
    "        cv2.circle(image,tuple(int(round(x*scale)) for x in keypoints['nose']), 1, (0,0,255), 2)\n",
    "        cv2.circle(image,tuple(int(round(x*scale)) for x in keypoints['mouth_left']), 1, (0,255,0), 2)\n",
    "        cv2.circle(image,tuple(int(round(x*scale)) for x in keypoints['mouth_right']), 1, (0,255,0), 2)\n",
    "\n",
    "    cv2.imwrite(\"result.jpg\", image)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75, allow_growth=True)\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False,gpu_options=gpu_options,))\n",
    "    with sess.as_default():\n",
    "        detector = Detector(sess)\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-de023a6c8d28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetScales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4540a0534fdd>\u001b[0m in \u001b[0;36mgetScales\u001b[0;34m(minsize, factor)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mtotal_boxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mminl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "detector.getScales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'sample.jpg'\n",
    "scale_width = 80\n",
    "\n",
    "minsize = 20\n",
    "threshold = [ 0.8, 0.8, 0.8]\n",
    "factor = 0.0 # ensure single scale pyramid\n",
    "\n",
    "frame_raw = cv2.imread(test_path+file)\n",
    "h, w = frame_raw.shape[0:2]\n",
    "scale = scale_width/w\n",
    "frame = cv2.resize(frame_raw,(int(w*scale),int(h*scale)))\n",
    "\n",
    "# Set Model\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75, allow_growth=True)\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False,gpu_options=gpu_options,))\n",
    "    with sess.as_default():\n",
    "        detector = Detector(sess)\n",
    "time.sleep(0.5)\n",
    "\n",
    "print('=== Starting Test ===')\n",
    "# Warmup\n",
    "detector_mtcnn_1.detect_faces(frame,minsize=minsize,threshold=threshold ,factor=factor,verbose=False)\n",
    "t.tic()\n",
    "for i in range(100):\n",
    "    result = detector_mtcnn_1.detect_faces(frame,minsize=minsize,threshold=threshold ,factor=factor,verbose=False)\n",
    "dt = t.toc()/100\n",
    "print('Facenet  Found '+str(len(result))+' face(s). Average time: '+str(round(dt*1000,2))+' ms. Average rate: '+\n",
    "      str(round(1/dt,2))+' Hz')\n",
    "# detector_mtcnn_1.toc_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((0,0))\n",
    "print(test)\n",
    "np.append(test,np.zeros((3,4,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1080,1920)\n",
    "a = np.zeros((1080,1920))\n",
    "a.shape == shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fydp)",
   "language": "python",
   "name": "fydp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
